{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data manipulation\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Pytorch geometric\n",
    "import torch   \n",
    "import torch_geometric\n",
    "from torch import nn, Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear, BCELoss, LSTM, Dropout\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import global_mean_pool as gap,  global_max_pool as gmp, global_add_pool as gsp\n",
    "\n",
    "#rdkit\n",
    "from rdkit import Chem                      \n",
    "from rdkit.Chem import GetAdjacencyMatrix       \n",
    "from scipy.sparse import coo_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#chemprop\n",
    "import chemprop\n",
    "from chemprop.args import TrainArgs, PredictArgs\n",
    "from chemprop.train import cross_validate, run_training, make_predictions\n",
    "\n",
    "#sklearn\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#shuffle\n",
    "from random import shuffle\n",
    "\n",
    "#GPU\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onek_encoding_unk(value, choices):\n",
    "    \"\"\"\n",
    "    Creates a one-hot encoding with an extra category for uncommon values.\n",
    "\n",
    "    :param value: The value for which the encoding should be one.\n",
    "    :param choices: A list of possible values.\n",
    "    :return: A one-hot encoding of the :code:`value` in a list of length :code:`len(choices) + 1`.\n",
    "             If :code:`value` is not in :code:`choices`, then the final element in the encoding is -1.\n",
    "    \"\"\"\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featurization_parameters:\n",
    "    \"\"\"\n",
    "    A class holding molecule featurization parameters as attributes.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        # Atom feature sizes\n",
    "        self.MAX_ATOMIC_NUM = 100\n",
    "        #for one-hot-encoding\n",
    "        self.ATOM_FEATURES = {\n",
    "            'atomic_num': list(range(self.MAX_ATOMIC_NUM)),\n",
    "            'degree': [0, 1, 2, 3, 4, 5],\n",
    "            'formal_charge': [-1, -2, 1, 2, 0],\n",
    "            'chiral_tag': [0, 1, 2, 3],\n",
    "            'num_Hs': [0, 1, 2, 3, 4],\n",
    "            'hybridization': [\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "                Chem.rdchem.HybridizationType.SP3D,\n",
    "                Chem.rdchem.HybridizationType.SP3D2\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        # Distance feature sizes\n",
    "        self.PATH_DISTANCE_BINS = list(range(10))\n",
    "        self.THREE_D_DISTANCE_MAX = 20\n",
    "        self.THREE_D_DISTANCE_STEP = 1\n",
    "        self.THREE_D_DISTANCE_BINS = list(range(0, self.THREE_D_DISTANCE_MAX + 1, self.THREE_D_DISTANCE_STEP))\n",
    "\n",
    "        # len(choices) + 1 to include room for uncommon values; + 2 at end for IsAromatic and mass\n",
    "        self.ATOM_FDIM = sum(len(choices) + 1 for choices in self.ATOM_FEATURES.values()) + 2\n",
    "        self.EXTRA_ATOM_FDIM = 0\n",
    "        self.BOND_FDIM = 14\n",
    "        self.EXTRA_BOND_FDIM = 0\n",
    "        self.REACTION_MODE = None\n",
    "        self.EXPLICIT_H = False\n",
    "        self.REACTION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = Featurization_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom: Chem.rdchem.Atom, functional_groups=None):\n",
    "    \"\"\"\n",
    "    Builds a feature vector for an atom.\n",
    "\n",
    "    :param atom: An RDKit atom.\n",
    "    :param functional_groups: A k-hot vector indicating the functional groups the atom belongs to.\n",
    "    :return: A list containing the atom features.\n",
    "    \"\"\"\n",
    "    if atom is None:\n",
    "        features = [0] * PARAMS.ATOM_FDIM\n",
    "    else:\n",
    "        features = onek_encoding_unk(atom.GetAtomicNum() - 1, PARAMS.ATOM_FEATURES['atomic_num']) + \\\n",
    "            onek_encoding_unk(atom.GetTotalDegree(), PARAMS.ATOM_FEATURES['degree']) + \\\n",
    "            onek_encoding_unk(atom.GetFormalCharge(), PARAMS.ATOM_FEATURES['formal_charge']) + \\\n",
    "            onek_encoding_unk(int(atom.GetChiralTag()), PARAMS.ATOM_FEATURES['chiral_tag']) + \\\n",
    "            onek_encoding_unk(int(atom.GetTotalNumHs()), PARAMS.ATOM_FEATURES['num_Hs']) + \\\n",
    "            onek_encoding_unk(int(atom.GetHybridization()), PARAMS.ATOM_FEATURES['hybridization']) + \\\n",
    "            [1 if atom.GetIsAromatic() else 0] + \\\n",
    "            [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "        if functional_groups is not None:\n",
    "            features += functional_groups\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bond_features(bond: Chem.rdchem.Bond):\n",
    "    \"\"\"\n",
    "    Builds a feature vector for a bond.\n",
    "\n",
    "    :param bond: An RDKit bond.\n",
    "    :return: A list containing the bond features.\n",
    "    \"\"\"\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (PARAMS.BOND_FDIM - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            (bond.GetIsConjugated() if bt is not None else 0),\n",
    "            (bond.IsInRing() if bt is not None else 0)\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MORGAN_RADIUS = 2\n",
    "MORGAN_NUM_BITS = 2048\n",
    "#a vector representation (1x2048) for molecular feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morgan_binary_features_generator(mol,\n",
    "                                     radius: int = MORGAN_RADIUS,\n",
    "                                     num_bits: int = MORGAN_NUM_BITS):\n",
    "    \"\"\"\n",
    "    Generates a binary Morgan fingerprint for a molecule.\n",
    "    :param mol: A molecule (i.e., either a SMILES or an RDKit molecule).\n",
    "    :param radius: Morgan fingerprint radius.\n",
    "    :param num_bits: Number of bits in Morgan fingerprint.\n",
    "    :return: A 1D numpy array containing the binary Morgan fingerprint.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(mol) if type(mol) == str else mol\n",
    "    features_vec = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n",
    "    features = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(features_vec, features)\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset,batch_size):\n",
    "    SMILES = dataset['SMILES']\n",
    "    data_list = []\n",
    "    \n",
    "    for smiles in SMILES:\n",
    "            \n",
    "        mol = Chem.MolFromSmiles(smiles)     \n",
    "        mol = Chem.AddHs(mol)  \n",
    "\n",
    "        #generate a global vector features (binary Morgan fingerprint) and convert them\n",
    "        mol_feature = torch.tensor(morgan_binary_features_generator(mol))\n",
    "\n",
    "        xs = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            x = atom_features(atom)\n",
    "            xs.append(x)\n",
    "            \n",
    "        x = torch.tensor(xs)\n",
    "        \n",
    "        edge_indices, edge_attrs = [], []\n",
    "        \n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "    \n",
    "            e = bond_features(bond)\n",
    "\n",
    "            edge_indices += [[i,j],[j,i]]\n",
    "            edge_attrs += [e, e]\n",
    "        \n",
    "        edge_index = torch.tensor(edge_indices)\n",
    "        edge_index = edge_index.t().to(torch.long).view(2, -1)\n",
    "        edge_attr = torch.tensor(edge_attrs).view(-1, 14)\n",
    "        \n",
    "        y = torch.tensor(int(dataset.loc[dataset['SMILES'] == smiles,'Activity'])) #response variable y\n",
    "\n",
    "        smi = smiles\n",
    "\n",
    "        # add smiles and num_feature as the attributes\n",
    "        data = Data(x=x, y=y, edge_index=edge_index, edge_attr = edge_attr, smiles=smi, mol_feature=mol_feature)  \n",
    "        data_list.append(data)   # store processed data into the list\n",
    "        \n",
    "    return DataLoader(data_list,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "    if hasattr(layer, 'reset_parameters'):\n",
    "        print(f'Reset trainable parameters of layer = {layer}')\n",
    "        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,train_loader):\n",
    "    \n",
    "    model.train()   \n",
    "    running_loss = 0 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = BCELoss()\n",
    "    for batch in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        label = batch.y.view(-1,1)\n",
    "        loss = criterion(outputs.float(),label.float())\n",
    "        \n",
    "\n",
    "        loss.backward()   # Compute the gradient of loss function \n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        running_loss += loss.item()\n",
    "        # probability that is larger than 0.5, classify as 1 \n",
    "\n",
    "        pred = (outputs >= 0.5).float()\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += (pred == label).float().sum()\n",
    "        \n",
    "    \n",
    "    loss = running_loss/len(train_loader)\n",
    "    accuracy = 100*correct/total\n",
    "    \n",
    "    train_accuracy.append(accuracy)\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: '+str(int(epoch)))\n",
    "        print('Train Loss: %.3f | Accuracy: %.3f'%(loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch,test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        criterion = BCELoss()\n",
    "        for batch in test_loader:\n",
    "        \n",
    "            outputs = model(batch)\n",
    "            label = batch.y.view(-1,1)\n",
    "\n",
    "            loss = criterion(outputs.float(), label.float())    \n",
    "            running_loss += loss.item()\n",
    "            # probability that is larger than 0.5, classify as 1 \n",
    "            pred = (outputs >= 0.5).float()\n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (pred == label).float().sum()\n",
    "    \n",
    "        loss = running_loss/len(test_loader)\n",
    "        accuracy = 100*correct/total\n",
    "    \n",
    "        test_accuracy.append(accuracy)\n",
    "        test_loss.append(loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print('Test Loss: %.3f | Accuracy: %.3f'%(loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set as a whole loader\n",
    "def test_metrics(test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        labels = []\n",
    "        preds = []\n",
    "        for batch in test_loader:\n",
    "            \n",
    "            labels += list(batch.y.view(-1,1).numpy())\n",
    "            preds += list(model(batch).detach().numpy())\n",
    "        \n",
    "        pred_labels = [1 if i > 0.5 else 0 for i in preds]\n",
    "        auc = roc_auc_score(list(labels), list(preds), average='weighted')\n",
    "        report = classification_report(labels, pred_labels,output_dict=True)\n",
    "        return auc, report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics):\n",
    "    AUC = [] #0\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    accuracy = []\n",
    "    for i in metrics:\n",
    "        AUC.append(i[0])\n",
    "        precision.append(i[1]['weighted avg']['precision'])\n",
    "        recall.append(i[1]['weighted avg']['recall'])\n",
    "        f1_score.append(i[1]['weighted avg']['f1-score'])\n",
    "        accuracy.append(i[1]['accuracy'])\n",
    "    \n",
    "    print('AUC:',np.mean(AUC),'+/-',np.std(AUC))\n",
    "    print('Accuracy:',np.mean(accuracy),'+/-',np.std(accuracy))\n",
    "    print('Precision:',np.mean(precision),'+/-',np.std(precision))\n",
    "    print('Recall:',np.mean(recall),'+/-',np.std(recall))\n",
    "    print('F1-score:',np.mean(f1_score),'+/-',np.std(f1_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNN analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,10)\n",
    "        self.linear4 = Linear(10, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.551 | Accuracy: 83.333\n",
      "Test Loss: 0.479 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.478680).  Saving model ...\n",
      "Validation loss decreased (0.478680 --> 0.397711).  Saving model ...\n",
      "Validation loss decreased (0.397711 --> 0.352046).  Saving model ...\n",
      "Validation loss decreased (0.352046 --> 0.316644).  Saving model ...\n",
      "Validation loss decreased (0.316644 --> 0.291640).  Saving model ...\n",
      "Validation loss decreased (0.291640 --> 0.276596).  Saving model ...\n",
      "Validation loss decreased (0.276596 --> 0.263993).  Saving model ...\n",
      "Validation loss decreased (0.263993 --> 0.257143).  Saving model ...\n",
      "Validation loss decreased (0.257143 --> 0.250829).  Saving model ...\n",
      "Validation loss decreased (0.250829 --> 0.245467).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.138 | Accuracy: 94.444\n",
      "Test Loss: 0.242 | Accuracy: 90.278\n",
      "Validation loss decreased (0.245467 --> 0.242009).  Saving model ...\n",
      "Validation loss decreased (0.242009 --> 0.239613).  Saving model ...\n",
      "Validation loss decreased (0.239613 --> 0.238264).  Saving model ...\n",
      "Validation loss decreased (0.238264 --> 0.237339).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.237339 --> 0.237156).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.058 | Accuracy: 98.785\n",
      "Test Loss: 0.245 | Accuracy: 90.278\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.707 | Accuracy: 45.139\n",
      "Test Loss: 0.604 | Accuracy: 81.250\n",
      "Validation loss decreased (inf --> 0.604399).  Saving model ...\n",
      "Validation loss decreased (0.604399 --> 0.447836).  Saving model ...\n",
      "Validation loss decreased (0.447836 --> 0.370372).  Saving model ...\n",
      "Validation loss decreased (0.370372 --> 0.327074).  Saving model ...\n",
      "Validation loss decreased (0.327074 --> 0.290004).  Saving model ...\n",
      "Validation loss decreased (0.290004 --> 0.268774).  Saving model ...\n",
      "Validation loss decreased (0.268774 --> 0.253319).  Saving model ...\n",
      "Validation loss decreased (0.253319 --> 0.243379).  Saving model ...\n",
      "Validation loss decreased (0.243379 --> 0.240316).  Saving model ...\n",
      "Validation loss decreased (0.240316 --> 0.231968).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.145 | Accuracy: 94.965\n",
      "Test Loss: 0.227 | Accuracy: 93.056\n",
      "Validation loss decreased (0.231968 --> 0.226571).  Saving model ...\n",
      "Validation loss decreased (0.226571 --> 0.225652).  Saving model ...\n",
      "Validation loss decreased (0.225652 --> 0.222091).  Saving model ...\n",
      "Validation loss decreased (0.222091 --> 0.217330).  Saving model ...\n",
      "Validation loss decreased (0.217330 --> 0.215029).  Saving model ...\n",
      "Validation loss decreased (0.215029 --> 0.213824).  Saving model ...\n",
      "Validation loss decreased (0.213824 --> 0.213562).  Saving model ...\n",
      "Validation loss decreased (0.213562 --> 0.211732).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.211732 --> 0.211444).  Saving model ...\n",
      "Epoch: 20\n",
      "Train Loss: 0.062 | Accuracy: 98.785\n",
      "Test Loss: 0.212 | Accuracy: 92.361\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Validation loss decreased (0.211444 --> 0.210717).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 30\n",
      "Train Loss: 0.035 | Accuracy: 99.479\n",
      "Test Loss: 0.215 | Accuracy: 93.056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.519 | Accuracy: 83.333\n",
      "Test Loss: 0.447 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.447351).  Saving model ...\n",
      "Validation loss decreased (0.447351 --> 0.391037).  Saving model ...\n",
      "Validation loss decreased (0.391037 --> 0.354707).  Saving model ...\n",
      "Validation loss decreased (0.354707 --> 0.330300).  Saving model ...\n",
      "Validation loss decreased (0.330300 --> 0.307280).  Saving model ...\n",
      "Validation loss decreased (0.307280 --> 0.298690).  Saving model ...\n",
      "Validation loss decreased (0.298690 --> 0.280739).  Saving model ...\n",
      "Validation loss decreased (0.280739 --> 0.277645).  Saving model ...\n",
      "Validation loss decreased (0.277645 --> 0.267864).  Saving model ...\n",
      "Validation loss decreased (0.267864 --> 0.266286).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.126 | Accuracy: 96.181\n",
      "Test Loss: 0.265 | Accuracy: 91.667\n",
      "Validation loss decreased (0.266286 --> 0.264986).  Saving model ...\n",
      "Validation loss decreased (0.264986 --> 0.263990).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.263990 --> 0.260968).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.051 | Accuracy: 99.132\n",
      "Test Loss: 0.275 | Accuracy: 92.361\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.690 | Accuracy: 52.431\n",
      "Test Loss: 0.662 | Accuracy: 84.028\n",
      "Validation loss decreased (inf --> 0.661684).  Saving model ...\n",
      "Validation loss decreased (0.661684 --> 0.569933).  Saving model ...\n",
      "Validation loss decreased (0.569933 --> 0.455637).  Saving model ...\n",
      "Validation loss decreased (0.455637 --> 0.391183).  Saving model ...\n",
      "Validation loss decreased (0.391183 --> 0.351441).  Saving model ...\n",
      "Validation loss decreased (0.351441 --> 0.319303).  Saving model ...\n",
      "Validation loss decreased (0.319303 --> 0.293537).  Saving model ...\n",
      "Validation loss decreased (0.293537 --> 0.278395).  Saving model ...\n",
      "Validation loss decreased (0.278395 --> 0.268998).  Saving model ...\n",
      "Validation loss decreased (0.268998 --> 0.259176).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.186 | Accuracy: 93.750\n",
      "Test Loss: 0.255 | Accuracy: 91.667\n",
      "Validation loss decreased (0.259176 --> 0.255290).  Saving model ...\n",
      "Validation loss decreased (0.255290 --> 0.249626).  Saving model ...\n",
      "Validation loss decreased (0.249626 --> 0.247764).  Saving model ...\n",
      "Validation loss decreased (0.247764 --> 0.245294).  Saving model ...\n",
      "Validation loss decreased (0.245294 --> 0.243808).  Saving model ...\n",
      "Validation loss decreased (0.243808 --> 0.240947).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.240947 --> 0.239654).  Saving model ...\n",
      "Validation loss decreased (0.239654 --> 0.237799).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.089 | Accuracy: 98.090\n",
      "Test Loss: 0.237 | Accuracy: 91.667\n",
      "Validation loss decreased (0.237799 --> 0.236651).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch: 30\n",
      "Train Loss: 0.050 | Accuracy: 99.479\n",
      "Test Loss: 0.244 | Accuracy: 92.361\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.681 | Accuracy: 50.347\n",
      "Test Loss: 0.542 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.542234).  Saving model ...\n",
      "Validation loss decreased (0.542234 --> 0.428596).  Saving model ...\n",
      "Validation loss decreased (0.428596 --> 0.386094).  Saving model ...\n",
      "Validation loss decreased (0.386094 --> 0.355801).  Saving model ...\n",
      "Validation loss decreased (0.355801 --> 0.333498).  Saving model ...\n",
      "Validation loss decreased (0.333498 --> 0.318262).  Saving model ...\n",
      "Validation loss decreased (0.318262 --> 0.309858).  Saving model ...\n",
      "Validation loss decreased (0.309858 --> 0.301919).  Saving model ...\n",
      "Validation loss decreased (0.301919 --> 0.295364).  Saving model ...\n",
      "Validation loss decreased (0.295364 --> 0.290528).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.201 | Accuracy: 93.750\n",
      "Test Loss: 0.286 | Accuracy: 90.278\n",
      "Validation loss decreased (0.290528 --> 0.286097).  Saving model ...\n",
      "Validation loss decreased (0.286097 --> 0.283959).  Saving model ...\n",
      "Validation loss decreased (0.283959 --> 0.280383).  Saving model ...\n",
      "Validation loss decreased (0.280383 --> 0.280318).  Saving model ...\n",
      "Validation loss decreased (0.280318 --> 0.279004).  Saving model ...\n",
      "Validation loss decreased (0.279004 --> 0.278362).  Saving model ...\n",
      "Validation loss decreased (0.278362 --> 0.276446).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.276446 --> 0.273040).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.131 | Accuracy: 97.396\n",
      "Test Loss: 0.274 | Accuracy: 92.361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9060416666666666 +/- 0.016563045937892658\n",
      "Accuracy: 0.9194444444444443 +/- 0.007081971546656668\n",
      "Precision: 0.919746629284548 +/- 0.00906868304630403\n",
      "Recall: 0.9194444444444443 +/- 0.007081971546656668\n",
      "F1-score: 0.9116807304424691 +/- 0.008129855558649557\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,250)\n",
    "        self.linear4 = Linear(250, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.490 | Accuracy: 80.729\n",
      "Test Loss: 0.382 | Accuracy: 84.028\n",
      "Validation loss decreased (inf --> 0.381951).  Saving model ...\n",
      "Validation loss decreased (0.381951 --> 0.285874).  Saving model ...\n",
      "Validation loss decreased (0.285874 --> 0.262060).  Saving model ...\n",
      "Validation loss decreased (0.262060 --> 0.256240).  Saving model ...\n",
      "Validation loss decreased (0.256240 --> 0.245984).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.019 | Accuracy: 100.000\n",
      "Test Loss: 0.279 | Accuracy: 89.583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.486 | Accuracy: 82.465\n",
      "Test Loss: 0.349 | Accuracy: 85.417\n",
      "Validation loss decreased (inf --> 0.348513).  Saving model ...\n",
      "Validation loss decreased (0.348513 --> 0.257684).  Saving model ...\n",
      "Validation loss decreased (0.257684 --> 0.239115).  Saving model ...\n",
      "Validation loss decreased (0.239115 --> 0.230649).  Saving model ...\n",
      "Validation loss decreased (0.230649 --> 0.214554).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.214554 --> 0.212653).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.025 | Accuracy: 100.000\n",
      "Test Loss: 0.237 | Accuracy: 93.056\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.474 | Accuracy: 83.681\n",
      "Test Loss: 0.380 | Accuracy: 84.722\n",
      "Validation loss decreased (inf --> 0.379907).  Saving model ...\n",
      "Validation loss decreased (0.379907 --> 0.301309).  Saving model ...\n",
      "Validation loss decreased (0.301309 --> 0.272918).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.021 | Accuracy: 100.000\n",
      "Test Loss: 0.314 | Accuracy: 91.667\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.492 | Accuracy: 81.250\n",
      "Test Loss: 0.372 | Accuracy: 84.722\n",
      "Validation loss decreased (inf --> 0.371614).  Saving model ...\n",
      "Validation loss decreased (0.371614 --> 0.279823).  Saving model ...\n",
      "Validation loss decreased (0.279823 --> 0.256187).  Saving model ...\n",
      "Validation loss decreased (0.256187 --> 0.252842).  Saving model ...\n",
      "Validation loss decreased (0.252842 --> 0.234576).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.022 | Accuracy: 99.826\n",
      "Test Loss: 0.266 | Accuracy: 92.361\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.490 | Accuracy: 78.993\n",
      "Test Loss: 0.386 | Accuracy: 84.722\n",
      "Validation loss decreased (inf --> 0.386271).  Saving model ...\n",
      "Validation loss decreased (0.386271 --> 0.304159).  Saving model ...\n",
      "Validation loss decreased (0.304159 --> 0.269066).  Saving model ...\n",
      "Validation loss decreased (0.269066 --> 0.249750).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Validation loss decreased (0.249750 --> 0.249529).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.026 | Accuracy: 99.653\n",
      "Test Loss: 0.273 | Accuracy: 93.056\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9044444444444444 +/- 0.02169224807490478\n",
      "Accuracy: 0.9125 +/- 0.012108052620946325\n",
      "Precision: 0.9085729128445598 +/- 0.013253302842692728\n",
      "Recall: 0.9125 +/- 0.012108052620946325\n",
      "F1-Score: 0.9068991561466959 +/- 0.013666741020387096\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,1000)\n",
    "        self.linear4 = Linear(1000, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.444 | Accuracy: 81.250\n",
      "Test Loss: 0.323 | Accuracy: 87.500\n",
      "Validation loss decreased (inf --> 0.322803).  Saving model ...\n",
      "Validation loss decreased (0.322803 --> 0.282121).  Saving model ...\n",
      "Validation loss decreased (0.282121 --> 0.274901).  Saving model ...\n",
      "Validation loss decreased (0.274901 --> 0.259772).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.016 | Accuracy: 99.826\n",
      "Test Loss: 0.344 | Accuracy: 90.278\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.468 | Accuracy: 80.556\n",
      "Test Loss: 0.319 | Accuracy: 89.583\n",
      "Validation loss decreased (inf --> 0.319155).  Saving model ...\n",
      "Validation loss decreased (0.319155 --> 0.261733).  Saving model ...\n",
      "Validation loss decreased (0.261733 --> 0.237595).  Saving model ...\n",
      "Validation loss decreased (0.237595 --> 0.223642).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.018 | Accuracy: 99.826\n",
      "Test Loss: 0.280 | Accuracy: 93.056\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.431 | Accuracy: 83.681\n",
      "Test Loss: 0.317 | Accuracy: 88.889\n",
      "Validation loss decreased (inf --> 0.317375).  Saving model ...\n",
      "Validation loss decreased (0.317375 --> 0.264246).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.015 | Accuracy: 100.000\n",
      "Test Loss: 0.347 | Accuracy: 91.667\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.436 | Accuracy: 84.375\n",
      "Test Loss: 0.306 | Accuracy: 90.278\n",
      "Validation loss decreased (inf --> 0.306314).  Saving model ...\n",
      "Validation loss decreased (0.306314 --> 0.271794).  Saving model ...\n",
      "Validation loss decreased (0.271794 --> 0.236845).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.019 | Accuracy: 99.826\n",
      "Test Loss: 0.293 | Accuracy: 92.361\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.462 | Accuracy: 84.375\n",
      "Test Loss: 0.354 | Accuracy: 88.889\n",
      "Validation loss decreased (inf --> 0.353779).  Saving model ...\n",
      "Validation loss decreased (0.353779 --> 0.292738).  Saving model ...\n",
      "Validation loss decreased (0.292738 --> 0.253222).  Saving model ...\n",
      "Validation loss decreased (0.253222 --> 0.251870).  Saving model ...\n",
      "Validation loss decreased (0.251870 --> 0.246554).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.017 | Accuracy: 99.826\n",
      "Test Loss: 0.286 | Accuracy: 90.278\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9049305555555556 +/- 0.015418230651399448\n",
      "Accuracy: 0.9166666666666666 +/- 0.009820927516479838\n",
      "Precision: 0.9138819055722894 +/- 0.011342375659872922\n",
      "Recall: 0.9166666666666666 +/- 0.009820927516479838\n",
      "F1-Score: 0.9107580226840865 +/- 0.011325650887375598\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [20,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,20)\n",
    "        self.linear2 = Linear(20,10)\n",
    "        self.linear4 = Linear(10, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.748 | Accuracy: 18.403\n",
      "Test Loss: 0.698 | Accuracy: 48.611\n",
      "Validation loss decreased (inf --> 0.697544).  Saving model ...\n",
      "Validation loss decreased (0.697544 --> 0.545820).  Saving model ...\n",
      "Validation loss decreased (0.545820 --> 0.432361).  Saving model ...\n",
      "Validation loss decreased (0.432361 --> 0.397378).  Saving model ...\n",
      "Validation loss decreased (0.397378 --> 0.361576).  Saving model ...\n",
      "Validation loss decreased (0.361576 --> 0.333137).  Saving model ...\n",
      "Validation loss decreased (0.333137 --> 0.312266).  Saving model ...\n",
      "Validation loss decreased (0.312266 --> 0.294004).  Saving model ...\n",
      "Validation loss decreased (0.294004 --> 0.280078).  Saving model ...\n",
      "Validation loss decreased (0.280078 --> 0.269963).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.193 | Accuracy: 93.576\n",
      "Test Loss: 0.261 | Accuracy: 89.583\n",
      "Validation loss decreased (0.269963 --> 0.260545).  Saving model ...\n",
      "Validation loss decreased (0.260545 --> 0.252158).  Saving model ...\n",
      "Validation loss decreased (0.252158 --> 0.243293).  Saving model ...\n",
      "Validation loss decreased (0.243293 --> 0.240353).  Saving model ...\n",
      "Validation loss decreased (0.240353 --> 0.236029).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.036 | Accuracy: 99.653\n",
      "Test Loss: 0.258 | Accuracy: 91.667\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.738 | Accuracy: 21.528\n",
      "Test Loss: 0.671 | Accuracy: 72.917\n",
      "Validation loss decreased (inf --> 0.670940).  Saving model ...\n",
      "Validation loss decreased (0.670940 --> 0.499998).  Saving model ...\n",
      "Validation loss decreased (0.499998 --> 0.398137).  Saving model ...\n",
      "Validation loss decreased (0.398137 --> 0.350767).  Saving model ...\n",
      "Validation loss decreased (0.350767 --> 0.315058).  Saving model ...\n",
      "Validation loss decreased (0.315058 --> 0.286728).  Saving model ...\n",
      "Validation loss decreased (0.286728 --> 0.266600).  Saving model ...\n",
      "Validation loss decreased (0.266600 --> 0.246402).  Saving model ...\n",
      "Validation loss decreased (0.246402 --> 0.232321).  Saving model ...\n",
      "Validation loss decreased (0.232321 --> 0.223540).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.104 | Accuracy: 96.875\n",
      "Test Loss: 0.215 | Accuracy: 92.361\n",
      "Validation loss decreased (0.223540 --> 0.215177).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.015 | Accuracy: 100.000\n",
      "Test Loss: 0.254 | Accuracy: 93.056\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.721 | Accuracy: 40.625\n",
      "Test Loss: 0.617 | Accuracy: 82.639\n",
      "Validation loss decreased (inf --> 0.616785).  Saving model ...\n",
      "Validation loss decreased (0.616785 --> 0.454772).  Saving model ...\n",
      "Validation loss decreased (0.454772 --> 0.411112).  Saving model ...\n",
      "Validation loss decreased (0.411112 --> 0.370938).  Saving model ...\n",
      "Validation loss decreased (0.370938 --> 0.333633).  Saving model ...\n",
      "Validation loss decreased (0.333633 --> 0.305560).  Saving model ...\n",
      "Validation loss decreased (0.305560 --> 0.283758).  Saving model ...\n",
      "Validation loss decreased (0.283758 --> 0.270166).  Saving model ...\n",
      "Validation loss decreased (0.270166 --> 0.263851).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.098 | Accuracy: 96.875\n",
      "Test Loss: 0.271 | Accuracy: 90.972\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.743 | Accuracy: 21.701\n",
      "Test Loss: 0.682 | Accuracy: 61.806\n",
      "Validation loss decreased (inf --> 0.682331).  Saving model ...\n",
      "Validation loss decreased (0.682331 --> 0.506098).  Saving model ...\n",
      "Validation loss decreased (0.506098 --> 0.393831).  Saving model ...\n",
      "Validation loss decreased (0.393831 --> 0.340279).  Saving model ...\n",
      "Validation loss decreased (0.340279 --> 0.302178).  Saving model ...\n",
      "Validation loss decreased (0.302178 --> 0.274793).  Saving model ...\n",
      "Validation loss decreased (0.274793 --> 0.256767).  Saving model ...\n",
      "Validation loss decreased (0.256767 --> 0.245092).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.088 | Accuracy: 97.569\n",
      "Test Loss: 0.239 | Accuracy: 91.667\n",
      "Validation loss decreased (0.245092 --> 0.239423).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.015 | Accuracy: 100.000\n",
      "Test Loss: 0.278 | Accuracy: 91.667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.554 | Accuracy: 83.333\n",
      "Test Loss: 0.498 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.498235).  Saving model ...\n",
      "Validation loss decreased (0.498235 --> 0.408103).  Saving model ...\n",
      "Validation loss decreased (0.408103 --> 0.362722).  Saving model ...\n",
      "Validation loss decreased (0.362722 --> 0.326760).  Saving model ...\n",
      "Validation loss decreased (0.326760 --> 0.297878).  Saving model ...\n",
      "Validation loss decreased (0.297878 --> 0.279389).  Saving model ...\n",
      "Validation loss decreased (0.279389 --> 0.267457).  Saving model ...\n",
      "Validation loss decreased (0.267457 --> 0.256578).  Saving model ...\n",
      "Validation loss decreased (0.256578 --> 0.247548).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.247548 --> 0.244755).  Saving model ...\n",
      "Epoch: 10\n",
      "Train Loss: 0.077 | Accuracy: 98.264\n",
      "Test Loss: 0.245 | Accuracy: 92.361\n",
      "Validation loss decreased (0.244755 --> 0.244639).  Saving model ...\n",
      "Validation loss decreased (0.244639 --> 0.244485).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.019 | Accuracy: 99.826\n",
      "Test Loss: 0.275 | Accuracy: 91.667\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9060416666666666 +/- 0.014508072997430276\n",
      "Accuracy: 0.913888888888889 +/- 0.007081971546656651\n",
      "Precision: 0.9116947760373536 +/- 0.006449467528059945\n",
      "Recall: 0.913888888888889 +/- 0.007081971546656651\n",
      "F1-Score: 0.9059422184139564 +/- 0.009749964326008685\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [500,250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,500)\n",
    "        self.linear2 = Linear(500,250)\n",
    "        self.linear4 = Linear(250, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.481 | Accuracy: 80.556\n",
      "Test Loss: 0.351 | Accuracy: 84.722\n",
      "Validation loss decreased (inf --> 0.351207).  Saving model ...\n",
      "Validation loss decreased (0.351207 --> 0.269777).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.003 | Accuracy: 100.000\n",
      "Test Loss: 0.443 | Accuracy: 90.972\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.490 | Accuracy: 83.333\n",
      "Test Loss: 0.347 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.347218).  Saving model ...\n",
      "Validation loss decreased (0.347218 --> 0.270485).  Saving model ...\n",
      "Validation loss decreased (0.270485 --> 0.234725).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.009 | Accuracy: 100.000\n",
      "Test Loss: 0.278 | Accuracy: 90.278\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.509 | Accuracy: 82.292\n",
      "Test Loss: 0.382 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.381507).  Saving model ...\n",
      "Validation loss decreased (0.381507 --> 0.327080).  Saving model ...\n",
      "Validation loss decreased (0.327080 --> 0.302947).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.003 | Accuracy: 100.000\n",
      "Test Loss: 0.417 | Accuracy: 90.278\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.487 | Accuracy: 80.556\n",
      "Test Loss: 0.341 | Accuracy: 86.806\n",
      "Validation loss decreased (inf --> 0.340948).  Saving model ...\n",
      "Validation loss decreased (0.340948 --> 0.307673).  Saving model ...\n",
      "Validation loss decreased (0.307673 --> 0.293154).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.019 | Accuracy: 99.479\n",
      "Test Loss: 0.402 | Accuracy: 93.056\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.471 | Accuracy: 81.250\n",
      "Test Loss: 0.373 | Accuracy: 84.722\n",
      "Validation loss decreased (inf --> 0.372563).  Saving model ...\n",
      "Validation loss decreased (0.372563 --> 0.310306).  Saving model ...\n",
      "Validation loss decreased (0.310306 --> 0.278704).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.006 | Accuracy: 99.826\n",
      "Test Loss: 0.373 | Accuracy: 88.889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8920833333333335 +/- 0.01998673364021589\n",
      "Accuracy: 0.9180555555555555 +/- 0.002777777777777812\n",
      "Precision: 0.916693519944759 +/- 0.0029809777101818514\n",
      "Recall: 0.9180555555555555 +/- 0.002777777777777812\n",
      "F1-Score: 0.9112297302994973 +/- 0.004144164460429964\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1000, 750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,1000)\n",
    "        self.linear2 = Linear(1000,750)\n",
    "        self.linear4 = Linear(750, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.457 | Accuracy: 80.035\n",
      "Test Loss: 0.325 | Accuracy: 86.111\n",
      "Validation loss decreased (inf --> 0.324861).  Saving model ...\n",
      "Validation loss decreased (0.324861 --> 0.269370).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.004 | Accuracy: 100.000\n",
      "Test Loss: 0.395 | Accuracy: 90.278\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.452 | Accuracy: 80.035\n",
      "Test Loss: 0.329 | Accuracy: 90.972\n",
      "Validation loss decreased (inf --> 0.329143).  Saving model ...\n",
      "Validation loss decreased (0.329143 --> 0.258457).  Saving model ...\n",
      "Validation loss decreased (0.258457 --> 0.254871).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.007 | Accuracy: 100.000\n",
      "Test Loss: 0.399 | Accuracy: 93.056\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.436 | Accuracy: 85.243\n",
      "Test Loss: 0.331 | Accuracy: 89.583\n",
      "Validation loss decreased (inf --> 0.331093).  Saving model ...\n",
      "Validation loss decreased (0.331093 --> 0.286758).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.022 | Accuracy: 99.653\n",
      "Test Loss: 0.446 | Accuracy: 89.583\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.426 | Accuracy: 82.118\n",
      "Test Loss: 0.302 | Accuracy: 90.278\n",
      "Validation loss decreased (inf --> 0.302082).  Saving model ...\n",
      "Validation loss decreased (0.302082 --> 0.288676).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.009 | Accuracy: 99.826\n",
      "Test Loss: 0.485 | Accuracy: 90.972\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.475 | Accuracy: 81.944\n",
      "Test Loss: 0.380 | Accuracy: 84.028\n",
      "Validation loss decreased (inf --> 0.380332).  Saving model ...\n",
      "Validation loss decreased (0.380332 --> 0.285204).  Saving model ...\n",
      "Validation loss decreased (0.285204 --> 0.280171).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.005 | Accuracy: 99.826\n",
      "Test Loss: 0.379 | Accuracy: 90.278\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.900625 +/- 0.018285659816869398\n",
      "Accuracy: 0.9125 +/- 0.012880025688188482\n",
      "Precision: 0.9082433779468768 +/- 0.01435870230375002\n",
      "Recall: 0.9125 +/- 0.012880025688188482\n",
      "F1-Score: 0.9079363730714591 +/- 0.013249202856802578\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [50,20,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,50)\n",
    "        self.linear2 = Linear(50,20)\n",
    "        self.linear3 = Linear(20,10)\n",
    "        self.linear4 = Linear(10, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.640 | Accuracy: 83.333\n",
      "Test Loss: 0.596 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.595925).  Saving model ...\n",
      "Validation loss decreased (0.595925 --> 0.442704).  Saving model ...\n",
      "Validation loss decreased (0.442704 --> 0.370737).  Saving model ...\n",
      "Validation loss decreased (0.370737 --> 0.328548).  Saving model ...\n",
      "Validation loss decreased (0.328548 --> 0.299439).  Saving model ...\n",
      "Validation loss decreased (0.299439 --> 0.283510).  Saving model ...\n",
      "Validation loss decreased (0.283510 --> 0.276034).  Saving model ...\n",
      "Validation loss decreased (0.276034 --> 0.275687).  Saving model ...\n",
      "Validation loss decreased (0.275687 --> 0.264118).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.086 | Accuracy: 99.306\n",
      "Test Loss: 0.258 | Accuracy: 90.972\n",
      "Validation loss decreased (0.264118 --> 0.257958).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch: 20\n",
      "Train Loss: 0.006 | Accuracy: 100.000\n",
      "Test Loss: 0.345 | Accuracy: 91.667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.654 | Accuracy: 70.486\n",
      "Test Loss: 0.576 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.576138).  Saving model ...\n",
      "Validation loss decreased (0.576138 --> 0.409311).  Saving model ...\n",
      "Validation loss decreased (0.409311 --> 0.343207).  Saving model ...\n",
      "Validation loss decreased (0.343207 --> 0.300275).  Saving model ...\n",
      "Validation loss decreased (0.300275 --> 0.289032).  Saving model ...\n",
      "Validation loss decreased (0.289032 --> 0.263037).  Saving model ...\n",
      "Validation loss decreased (0.263037 --> 0.238788).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Validation loss decreased (0.238788 --> 0.238043).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.019 | Accuracy: 99.826\n",
      "Test Loss: 0.251 | Accuracy: 93.056\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.725 | Accuracy: 22.569\n",
      "Test Loss: 0.685 | Accuracy: 72.222\n",
      "Validation loss decreased (inf --> 0.685249).  Saving model ...\n",
      "Validation loss decreased (0.685249 --> 0.573123).  Saving model ...\n",
      "Validation loss decreased (0.573123 --> 0.431328).  Saving model ...\n",
      "Validation loss decreased (0.431328 --> 0.377367).  Saving model ...\n",
      "Validation loss decreased (0.377367 --> 0.323974).  Saving model ...\n",
      "Validation loss decreased (0.323974 --> 0.277962).  Saving model ...\n",
      "Validation loss decreased (0.277962 --> 0.256096).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.033 | Accuracy: 99.479\n",
      "Test Loss: 0.322 | Accuracy: 92.361\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.573 | Accuracy: 83.333\n",
      "Test Loss: 0.545 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.545083).  Saving model ...\n",
      "Validation loss decreased (0.545083 --> 0.446696).  Saving model ...\n",
      "Validation loss decreased (0.446696 --> 0.356688).  Saving model ...\n",
      "Validation loss decreased (0.356688 --> 0.307994).  Saving model ...\n",
      "Validation loss decreased (0.307994 --> 0.265083).  Saving model ...\n",
      "Validation loss decreased (0.265083 --> 0.249728).  Saving model ...\n",
      "Validation loss decreased (0.249728 --> 0.244612).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.016 | Accuracy: 100.000\n",
      "Test Loss: 0.287 | Accuracy: 91.667\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=10, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=10, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.716 | Accuracy: 28.472\n",
      "Test Loss: 0.676 | Accuracy: 82.639\n",
      "Validation loss decreased (inf --> 0.676204).  Saving model ...\n",
      "Validation loss decreased (0.676204 --> 0.522407).  Saving model ...\n",
      "Validation loss decreased (0.522407 --> 0.415748).  Saving model ...\n",
      "Validation loss decreased (0.415748 --> 0.349671).  Saving model ...\n",
      "Validation loss decreased (0.349671 --> 0.300835).  Saving model ...\n",
      "Validation loss decreased (0.300835 --> 0.271447).  Saving model ...\n",
      "Validation loss decreased (0.271447 --> 0.265909).  Saving model ...\n",
      "Validation loss decreased (0.265909 --> 0.247817).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.030 | Accuracy: 99.306\n",
      "Test Loss: 0.269 | Accuracy: 93.750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.90625 +/- 0.013093546968725554\n",
      "Accuracy: 0.9180555555555555 +/- 0.01020620726159659\n",
      "Precision: 0.9162778153204384 +/- 0.01180417318758369\n",
      "Recall: 0.9180555555555555 +/- 0.01020620726159659\n",
      "F1-Score: 0.9108043659636218 +/- 0.011957614768403063\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [500,250,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,500)\n",
    "        self.linear2 = Linear(500,250)\n",
    "        self.linear3 = Linear(250,100)\n",
    "        self.linear4 = Linear(100, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=100, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.518 | Accuracy: 83.333\n",
      "Test Loss: 0.374 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.374346).  Saving model ...\n",
      "Validation loss decreased (0.374346 --> 0.299280).  Saving model ...\n",
      "Validation loss decreased (0.299280 --> 0.267340).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.002 | Accuracy: 100.000\n",
      "Test Loss: 0.508 | Accuracy: 89.583\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=100, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.525 | Accuracy: 77.778\n",
      "Test Loss: 0.363 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.362754).  Saving model ...\n",
      "Validation loss decreased (0.362754 --> 0.313567).  Saving model ...\n",
      "Validation loss decreased (0.313567 --> 0.270081).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.005 | Accuracy: 99.826\n",
      "Test Loss: 0.485 | Accuracy: 88.889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=100, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.540 | Accuracy: 83.333\n",
      "Test Loss: 0.397 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.396999).  Saving model ...\n",
      "Validation loss decreased (0.396999 --> 0.355991).  Saving model ...\n",
      "Validation loss decreased (0.355991 --> 0.334749).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.002 | Accuracy: 100.000\n",
      "Test Loss: 0.522 | Accuracy: 88.889\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=100, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.504 | Accuracy: 83.333\n",
      "Test Loss: 0.359 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.358876).  Saving model ...\n",
      "Validation loss decreased (0.358876 --> 0.296888).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.004 | Accuracy: 100.000\n",
      "Test Loss: 0.426 | Accuracy: 91.667\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=250, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=250, out_features=100, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.508 | Accuracy: 78.819\n",
      "Test Loss: 0.387 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.386508).  Saving model ...\n",
      "Validation loss decreased (0.386508 --> 0.342786).  Saving model ...\n",
      "Validation loss decreased (0.342786 --> 0.306312).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.014 | Accuracy: 99.306\n",
      "Test Loss: 0.477 | Accuracy: 88.194\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8897916666666668 +/- 0.02141727913809341\n",
      "Accuracy: 0.913888888888889 +/- 0.008333333333333356\n",
      "Precision: 0.9122939351627937 +/- 0.006989355462418052\n",
      "Recall: 0.913888888888889 +/- 0.008333333333333356\n",
      "F1-Score: 0.9088619611916652 +/- 0.008436960853723306\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1000,750,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "    \n",
    "        #before the Attention Mechanism, parse in a fully connected network and output a 50 dimensional vector \n",
    "        self.hidden = 50  \n",
    "        self.in_head = 5 #repeat the mechanism for 5 times\n",
    "        self.conv1 = GATConv(in_channels = 133, \n",
    "                             out_channels = self.hidden, \n",
    "                             heads=self.in_head, concat=False) #set concat to be False, so it will take average instead\n",
    "\n",
    "        \n",
    "        #fully connected layers\n",
    "        self.linear1 = Linear(self.hidden+2048,1000)\n",
    "        self.linear2 = Linear(1000,750)\n",
    "        self.linear3 = Linear(750,500)\n",
    "        self.linear4 = Linear(500, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \n",
    "        x, edge_index, batch_index, mol_feature = data.x, data.edge_index, data.batch, data.mol_feature    \n",
    "        #extract node vectors, edge_index, batch index, and binary morgan fingerprint \n",
    "        \n",
    "        x = self.conv1(x.float(), edge_index)\n",
    "\n",
    "        #aggregate the learned local node feature to capture the global property \n",
    "        #here, we apply global_mean_pool over the updated node feature\n",
    "        x = gap(x,batch_index)\n",
    "        #also include some other global information i.e. binary morgan fingerprint\n",
    "        x = torch.cat([x, mol_feature.reshape(data.num_graphs,2048)],dim=1)\n",
    "\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = torch.sigmoid(self.linear4(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.423 | Accuracy: 83.507\n",
      "Test Loss: 0.340 | Accuracy: 86.806\n",
      "Validation loss decreased (inf --> 0.339770).  Saving model ...\n",
      "Validation loss decreased (0.339770 --> 0.290800).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.002 | Accuracy: 100.000\n",
      "Test Loss: 0.498 | Accuracy: 88.889\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 2 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.526 | Accuracy: 83.333\n",
      "Test Loss: 0.387 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.387105).  Saving model ...\n",
      "Validation loss decreased (0.387105 --> 0.289618).  Saving model ...\n",
      "Validation loss decreased (0.289618 --> 0.285977).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.002 | Accuracy: 100.000\n",
      "Test Loss: 0.385 | Accuracy: 90.972\n",
      "EarlyStopping counter: 8 out of 10\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 3 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.469 | Accuracy: 79.167\n",
      "Test Loss: 0.356 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.356025).  Saving model ...\n",
      "Validation loss decreased (0.356025 --> 0.346720).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.001 | Accuracy: 100.000\n",
      "Test Loss: 0.512 | Accuracy: 90.972\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 4 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.461 | Accuracy: 83.507\n",
      "Test Loss: 0.332 | Accuracy: 88.889\n",
      "Validation loss decreased (inf --> 0.332047).  Saving model ...\n",
      "Validation loss decreased (0.332047 --> 0.247062).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.003 | Accuracy: 100.000\n",
      "Test Loss: 0.456 | Accuracy: 92.361\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "Split 5 ......\n",
      "Reset trainable parameters of layer = Linear(133, 250, bias=False)\n",
      "Reset trainable parameters of layer = GATConv(133, 50, heads=5)\n",
      "Reset trainable parameters of layer = Linear(in_features=2098, out_features=1000, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=1000, out_features=750, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=750, out_features=500, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=500, out_features=1, bias=True)\n",
      "Epoch: 0\n",
      "Train Loss: 0.467 | Accuracy: 79.861\n",
      "Test Loss: 0.356 | Accuracy: 83.333\n",
      "Validation loss decreased (inf --> 0.356426).  Saving model ...\n",
      "Validation loss decreased (0.356426 --> 0.285277).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 10\n",
      "EarlyStopping counter: 2 out of 10\n",
      "EarlyStopping counter: 3 out of 10\n",
      "EarlyStopping counter: 4 out of 10\n",
      "EarlyStopping counter: 5 out of 10\n",
      "EarlyStopping counter: 6 out of 10\n",
      "EarlyStopping counter: 7 out of 10\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch: 10\n",
      "Train Loss: 0.005 | Accuracy: 100.000\n",
      "Test Loss: 0.471 | Accuracy: 90.972\n",
      "EarlyStopping counter: 9 out of 10\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "test_losses= []\n",
    "metrics = []\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print('Split '+str(i+1)+' ......')\n",
    "    train_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/train_split'+str(i+1)+'.csv')\n",
    "    test_set = pd.read_csv('C:/Users/jimmy/Desktop/FYP/test_split'+str(i+1)+'.csv')\n",
    "    train_loader = data_process(train_set,32)\n",
    "    test_loader = data_process(test_set,len(test_set))\n",
    "    \n",
    "    model = GAT().float()\n",
    "    model.apply(reset_weights)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    #update the model parameters with 50 epochs\n",
    "    for epoch in range(100):\n",
    "        train(epoch,train_loader)\n",
    "        test(epoch,test_loader)\n",
    "        \n",
    "        early_stopping(test_loss[-1],model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    auc, report = test_metrics(test_loader)\n",
    "    metric = [auc,report]\n",
    "    \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_acc.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    metrics.append(metric)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8995833333333334 +/- 0.01902118701752223\n",
      "Accuracy: 0.9138888888888888 +/- 0.007081971546656651\n",
      "Precision: 0.9100674017550077 +/- 0.007280782787461408\n",
      "Recall: 0.9138888888888888 +/- 0.007081971546656651\n",
      "F1-Score: 0.9088795223324763 +/- 0.009652213392634194\n"
     ]
    }
   ],
   "source": [
    "print_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
